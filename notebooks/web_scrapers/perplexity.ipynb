{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Perplexity AI Scraper - Testing Notebook\n",
    "\n",
    "Test the Perplexity AI scraper implementation:\n",
    "- AI-powered search with citations\n",
    "- Country-specific search\n",
    "- Batch prompt processing\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup - Use Local Development Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using source from: /Users/ns/Desktop/projects/sdk-python/src\n",
      "API Token: 7011787d-2...3336\n",
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add local src to path (use development version, not installed)\n",
    "project_root = Path.cwd().parent\n",
    "src_path = project_root / \"src\"\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "print(f\"Using source from: {src_path}\")\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(project_root / \".env\")\n",
    "\n",
    "# Get API token\n",
    "API_TOKEN = os.getenv(\"BRIGHTDATA_API_TOKEN\")\n",
    "if not API_TOKEN:\n",
    "    raise ValueError(\"BRIGHTDATA_API_TOKEN not found in environment\")\n",
    "\n",
    "print(f\"API Token: {API_TOKEN[:10]}...{API_TOKEN[-4:]}\")\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Initialize Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brightdata module location: /Users/ns/Desktop/projects/sdk-python/src/brightdata/__init__.py\n",
      "\n",
      "PerplexityScraper: PerplexityScraper\n",
      "\n",
      "Available methods:\n",
      "['normalize_result', 'scrape', 'scrape_async', 'search', 'search_fetch', 'search_fetch_sync', 'search_status', 'search_status_sync', 'search_sync', 'search_trigger', 'search_trigger_sync']\n"
     ]
    }
   ],
   "source": [
    "from brightdata import BrightDataClient\n",
    "\n",
    "# Verify we're using local version\n",
    "import brightdata\n",
    "print(f\"brightdata module location: {brightdata.__file__}\")\n",
    "\n",
    "# Initialize client\n",
    "client = BrightDataClient(token=API_TOKEN)\n",
    "\n",
    "# Verify Perplexity scraper is accessible\n",
    "print(f\"\\nPerplexityScraper: {type(client.scrape.perplexity).__name__}\")\n",
    "\n",
    "# Check for scraper methods\n",
    "print(\"\\nAvailable methods:\")\n",
    "print([m for m in dir(client.scrape.perplexity) if not m.startswith('_') and callable(getattr(client.scrape.perplexity, m))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 1: Single Prompt Search\n",
    "\n",
    "Basic search with a single prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching Perplexity with prompt:\n",
      "  'What are the latest trends in artificial intelligence in 2026?'\n",
      "\n",
      "This may take up to 11 minutes...\n",
      "\n",
      "Success: True\n",
      "Status: ready\n",
      "Snapshot ID: sd_mkuuq1g21ftyx65xqk\n",
      "Cost: $0.0050\n",
      "\n",
      "--- Perplexity Response ---\n",
      "Available keys: ['url', 'prompt', 'answer_html', 'answer_text', 'answer_text_markdown', 'sources', 'source_html', 'is_shopping_data', 'shopping_data', 'index', 'response_raw', 'answer_section_html', 'exported_markdown', 'related_prompts', 'citations', 'web_search_query', 'timestamp', 'input']\n",
      "\n",
      "Prompt: What are the latest trends in artificial intelligence in 2026?...\n",
      "\n",
      "Answer (first 500 chars):\n",
      "  <html lang=\"ru-RU\" data-color-scheme=\"light\" dir=\"ltr\">\n",
      "<head>\n",
      "<meta name=\"min-version\" content=\"1769380062633\">\n",
      "<meta name=\"version\" content=\"ed51641\">\n",
      "<meta charset=\"utf-8\">\n",
      "<link rel=\"preconnect\" crossorigin href=\"https://pplx-next-static-public.perplexity.ai\">\n",
      "<link rel=\"preconnect\" crossorigin href=\"https://r2cdn.perplexity.ai\">\n",
      "<link rel=\"preload\" href=\"https://r2cdn.perplexity.ai/fonts/PPLX-Sans-Beta-VF.woff2\" as=\"font\" type=\"font/woff2\" crossorigin>\n",
      "<link rel=\"preload\" href=\"https://r2cd...\n",
      "\n",
      "Citations (10 sources):\n",
      "  1. Top 10 AI Trends to Watch in 2026\n",
      "     URL: https://www.usaii.org/ai-insights/top-10-ai-trends-to-watch-\n",
      "  2. What's next in AI: 7 trends to watch in 2026\n",
      "     URL: https://news.microsoft.com/source/features/ai/whats-next-in-\n",
      "  3. Top 8 AI Predictions for 2026\n",
      "     URL: https://www.linkedin.com/pulse/top-8-ai-predictions-2026-jea\n",
      "  4. 2026 AI trends - Staying Competitive - I by IMD\n",
      "     URL: https://www.imd.org/ibyimd/artificial-intelligence/2026-ai-t\n",
      "  5. AI trends for 2026\n",
      "     URL: https://www.reddit.com/r/AINewsAndTrends/comments/1px119q/ai\n"
     ]
    }
   ],
   "source": [
    "# Test single prompt search\n",
    "PROMPT = \"What are the latest trends in artificial intelligence in 2026?\"\n",
    "\n",
    "print(\"Searching Perplexity with prompt:\")\n",
    "print(f\"  '{PROMPT}'\")\n",
    "print(\"\\nThis may take up to 11 minutes...\\n\")\n",
    "\n",
    "async with client.scrape.perplexity.engine:\n",
    "    result = await client.scrape.perplexity.search(\n",
    "        prompt=PROMPT,\n",
    "        country=\"US\",\n",
    "        poll_timeout=660\n",
    "    )\n",
    "\n",
    "print(f\"Success: {result.success}\")\n",
    "print(f\"Status: {result.status}\")\n",
    "print(f\"Snapshot ID: {result.snapshot_id}\")\n",
    "print(f\"Cost: ${result.cost:.4f}\" if result.cost else \"Cost: N/A\")\n",
    "\n",
    "if result.success and result.data:\n",
    "    print(\"\\n--- Perplexity Response ---\")\n",
    "    data = result.data\n",
    "    \n",
    "    # Handle list response\n",
    "    if isinstance(data, list) and len(data) > 0:\n",
    "        data = data[0]\n",
    "    \n",
    "    print(f\"Available keys: {list(data.keys()) if isinstance(data, dict) else 'N/A'}\")\n",
    "    \n",
    "    if isinstance(data, dict):\n",
    "        # Check for error\n",
    "        if 'error' in data:\n",
    "            print(f\"\\nAPI Error: {data.get('error')}\")\n",
    "            print(f\"Error Code: {data.get('error_code')}\")\n",
    "        else:\n",
    "            print(f\"\\nPrompt: {data.get('prompt', 'N/A')[:100]}...\")\n",
    "            \n",
    "            # Answer\n",
    "            answer = data.get('answer_html', data.get('answer', 'N/A'))\n",
    "            if answer and answer != 'N/A':\n",
    "                print(\"\\nAnswer (first 500 chars):\")\n",
    "                print(f\"  {str(answer)[:500]}...\")\n",
    "            \n",
    "            # Citations\n",
    "            citations = data.get('citations', [])\n",
    "            if citations:\n",
    "                print(f\"\\nCitations ({len(citations)} sources):\")\n",
    "                for i, cite in enumerate(citations[:5]):\n",
    "                    print(f\"  {i+1}. {cite.get('title', 'N/A')[:50]}\")\n",
    "                    print(f\"     URL: {cite.get('url', 'N/A')[:60]}\")\n",
    "            \n",
    "            # Follow-up questions\n",
    "            followups = data.get('suggested_followup', [])\n",
    "            if followups:\n",
    "                print(\"\\nSuggested follow-ups:\")\n",
    "                for q in followups[:3]:\n",
    "                    print(f\"  - {q}\")\n",
    "else:\n",
    "    print(f\"\\nError: {result.error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 2: Search with Different Country\n",
    "\n",
    "Test country-specific search context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test search with different country\n",
    "PROMPT = \"What are the top news stories today?\"\n",
    "\n",
    "print(\"Searching with country=GB (UK):\")\n",
    "print(f\"  '{PROMPT}'\")\n",
    "print(\"\\nThis may take up to 11 minutes...\\n\")\n",
    "\n",
    "async with client.scrape.perplexity.engine:\n",
    "    result = await client.scrape.perplexity.search(\n",
    "        prompt=PROMPT,\n",
    "        country=\"GB\",\n",
    "        poll_timeout=660\n",
    "    )\n",
    "\n",
    "print(f\"Success: {result.success}\")\n",
    "print(f\"Status: {result.status}\")\n",
    "print(f\"Snapshot ID: {result.snapshot_id}\")\n",
    "\n",
    "if result.success and result.data:\n",
    "    print(\"\\n--- Perplexity Response (UK) ---\")\n",
    "    data = result.data\n",
    "    \n",
    "    if isinstance(data, list) and len(data) > 0:\n",
    "        data = data[0]\n",
    "    \n",
    "    if isinstance(data, dict) and 'error' not in data:\n",
    "        answer = data.get('answer_html', data.get('answer', 'N/A'))\n",
    "        if answer and answer != 'N/A':\n",
    "            print(\"Answer (first 500 chars):\")\n",
    "            print(f\"  {str(answer)[:500]}...\")\n",
    "        \n",
    "        citations = data.get('citations', [])\n",
    "        if citations:\n",
    "            print(f\"\\nCitations ({len(citations)} sources):\")\n",
    "            for i, cite in enumerate(citations[:3]):\n",
    "                print(f\"  {i+1}. {cite.get('domain', 'N/A')} - {cite.get('title', 'N/A')[:40]}\")\n",
    "    elif isinstance(data, dict) and 'error' in data:\n",
    "        print(f\"API Error: {data.get('error')}\")\n",
    "else:\n",
    "    print(f\"\\nError: {result.error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 3: Batch Prompts\n",
    "\n",
    "Test multiple prompts in a single request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test batch prompts\n",
    "PROMPTS = [\n",
    "    \"What is Python programming language?\",\n",
    "    \"What is machine learning?\"\n",
    "]\n",
    "\n",
    "print(f\"Batch search with {len(PROMPTS)} prompts:\")\n",
    "for i, p in enumerate(PROMPTS):\n",
    "    print(f\"  {i+1}. {p}\")\n",
    "print(\"\\nThis may take up to 11 minutes...\\n\")\n",
    "\n",
    "async with client.scrape.perplexity.engine:\n",
    "    result = await client.scrape.perplexity.search(\n",
    "        prompt=PROMPTS,\n",
    "        country=\"US\",\n",
    "        poll_timeout=660\n",
    "    )\n",
    "\n",
    "print(f\"Success: {result.success}\")\n",
    "print(f\"Status: {result.status}\")\n",
    "print(f\"Snapshot ID: {result.snapshot_id}\")\n",
    "print(f\"Cost: ${result.cost:.4f}\" if result.cost else \"Cost: N/A\")\n",
    "\n",
    "if result.success and result.data:\n",
    "    print(\"\\n--- Batch Results ---\")\n",
    "    data = result.data\n",
    "    \n",
    "    if isinstance(data, list):\n",
    "        print(f\"Number of responses: {len(data)}\")\n",
    "        \n",
    "        for i, item in enumerate(data):\n",
    "            print(f\"\\n=== Response {i+1} ===\")\n",
    "            if isinstance(item, dict):\n",
    "                if 'error' in item:\n",
    "                    print(f\"  Error: {item.get('error')}\")\n",
    "                else:\n",
    "                    prompt = item.get('prompt', 'N/A')\n",
    "                    print(f\"  Prompt: {prompt[:60]}...\")\n",
    "                    \n",
    "                    answer = item.get('answer_html', item.get('answer', ''))\n",
    "                    if answer:\n",
    "                        print(f\"  Answer: {str(answer)[:200]}...\")\n",
    "                    \n",
    "                    citations = item.get('citations', [])\n",
    "                    print(f\"  Citations: {len(citations)} sources\")\n",
    "    else:\n",
    "        print(f\"Unexpected data type: {type(data)}\")\n",
    "else:\n",
    "    print(f\"\\nError: {result.error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 4: Technical Question\n",
    "\n",
    "Test with a technical/coding question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test technical question\n",
    "PROMPT = \"How do I implement async/await in Python? Give me a simple example.\"\n",
    "\n",
    "print(\"Technical question:\")\n",
    "print(f\"  '{PROMPT}'\")\n",
    "print(\"\\nThis may take up to 11 minutes...\\n\")\n",
    "\n",
    "async with client.scrape.perplexity.engine:\n",
    "    result = await client.scrape.perplexity.search(\n",
    "        prompt=PROMPT,\n",
    "        country=\"US\",\n",
    "        poll_timeout=660\n",
    "    )\n",
    "\n",
    "print(f\"Success: {result.success}\")\n",
    "print(f\"Status: {result.status}\")\n",
    "\n",
    "if result.success and result.data:\n",
    "    data = result.data\n",
    "    if isinstance(data, list) and len(data) > 0:\n",
    "        data = data[0]\n",
    "    \n",
    "    if isinstance(data, dict) and 'error' not in data:\n",
    "        print(\"\\n--- Technical Answer ---\")\n",
    "        answer = data.get('answer_html', data.get('answer', 'N/A'))\n",
    "        print(f\"{str(answer)[:1000]}...\" if len(str(answer)) > 1000 else answer)\n",
    "        \n",
    "        # Web search queries used\n",
    "        queries = data.get('web_search_query', [])\n",
    "        if queries:\n",
    "            print(f\"\\nSearch queries used: {queries}\")\n",
    "    elif isinstance(data, dict) and 'error' in data:\n",
    "        print(f\"\\nAPI Error: {data.get('error')}\")\n",
    "else:\n",
    "    print(f\"\\nError: {result.error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 5: Export Raw Data\n",
    "\n",
    "Export the raw response data to a JSON file for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export raw data to JSON file for inspection\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "if result.success and result.data:\n",
    "    output_file = Path.cwd() / \"perplexity_result.json\"\n",
    "\n",
    "    export_data = {\n",
    "        \"success\": result.success,\n",
    "        \"status\": result.status,\n",
    "        \"snapshot_id\": result.snapshot_id,\n",
    "        \"cost\": result.cost,\n",
    "        \"row_count\": result.row_count,\n",
    "        \"data\": result.data,\n",
    "        \"error\": result.error,\n",
    "    }\n",
    "\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(export_data, f, indent=2, default=str)\n",
    "\n",
    "    print(f\"Exported to: {output_file}\")\n",
    "    print(f\"\\nData type: {type(result.data)}\")\n",
    "else:\n",
    "    print(\"No data to export\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 6: Check Timing Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check timing metadata from last result\n",
    "print(\"=== Timing Metadata ===\")\n",
    "print(f\"trigger_sent_at: {result.trigger_sent_at}\")\n",
    "print(f\"snapshot_id_received_at: {result.snapshot_id_received_at}\")\n",
    "print(f\"snapshot_polled_at: {result.snapshot_polled_at}\")\n",
    "print(f\"data_fetched_at: {result.data_fetched_at}\")\n",
    "print(f\"\\nrow_count: {result.row_count}\")\n",
    "print(f\"cost: {result.cost}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "### PerplexityScraper Methods\n",
    "\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| `search(prompt, country, ...)` | Async search with prompt(s) |\n",
    "| `search_sync(...)` | Sync version |\n",
    "| `search_trigger(...)` | Manual trigger (returns Job) |\n",
    "| `search_status(snapshot_id)` | Check status |\n",
    "| `search_fetch(snapshot_id)` | Fetch results |\n",
    "\n",
    "### Response Fields\n",
    "\n",
    "| Field | Description |\n",
    "|-------|-------------|\n",
    "| `url` | Perplexity search URL generated |\n",
    "| `prompt` | The full prompt with context |\n",
    "| `answer_html` | HTML-formatted response |\n",
    "| `suggested_followup` | Suggested follow-up questions |\n",
    "| `citations` | Citation sources with domain, title, url |\n",
    "| `web_search_query` | Search queries used |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
