{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”“ Web Unlocker - Scrape Any Website\n",
    "\n",
    "Test the Web Unlocker API for scraping any website with anti-bot bypass:\n",
    "- Basic HTML scraping\n",
    "- Batch URL scraping\n",
    "- Country-specific proxies\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "API_TOKEN = os.getenv(\"BRIGHTDATA_API_TOKEN\")\n",
    "if not API_TOKEN:\n",
    "    raise ValueError(\"Set BRIGHTDATA_API_TOKEN in .env file\")\n",
    "\n",
    "print(f\"API Token: {API_TOKEN[:10]}...{API_TOKEN[-4:]}\")\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brightdata import BrightDataClient\n",
    "\n",
    "# Initialize client\n",
    "client = BrightDataClient(token=API_TOKEN)\n",
    "\n",
    "print(\"Client initialized\")\n",
    "print(f\"Default Web Unlocker zone: {client.web_unlocker_zone}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 1: Basic HTML Scraping\n",
    "\n",
    "Scrape a simple webpage and get raw HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://example.com\"\n",
    "\n",
    "print(f\"Scraping: {URL}\\n\")\n",
    "\n",
    "async with client:\n",
    "    result = await client.scrape_url(\n",
    "        url=URL,\n",
    "        response_format=\"raw\"\n",
    "    )\n",
    "\n",
    "print(f\"Success: {result.success}\")\n",
    "print(f\"Status: {result.status}\")\n",
    "print(f\"Method: {result.method}\")\n",
    "\n",
    "if result.success and result.data:\n",
    "    html = result.data\n",
    "    print(f\"\\nHTML length: {len(html)} characters\")\n",
    "    print(\"\\nFirst 500 characters:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(html[:500])\n",
    "    print(\"-\" * 50)\n",
    "else:\n",
    "    print(f\"\\nError: {result.error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 2: Country-Specific Proxy\n",
    "\n",
    "Use a proxy from a specific country to get localized content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing country-specific proxies...\n",
      "\n",
      "Country: US\n",
      "  Success: True\n",
      "  HTML length: 513 chars\n",
      "\n",
      "Country: GB\n",
      "  Success: True\n",
      "  HTML length: 513 chars\n",
      "\n",
      "Country: DE\n",
      "  Success: True\n",
      "  HTML length: 513 chars\n",
      "\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://example.com\"\n",
    "\n",
    "print(\"Testing country-specific proxies...\\n\")\n",
    "\n",
    "countries = [\"US\", \"GB\", \"DE\"]\n",
    "\n",
    "async with client:\n",
    "    for country in countries:\n",
    "        print(f\"Country: {country}\")\n",
    "        result = await client.scrape_url(\n",
    "            url=URL,\n",
    "            country=country,\n",
    "            response_format=\"raw\"\n",
    "        )\n",
    "        \n",
    "        if result.success and result.data:\n",
    "            print(f\"  Success: {result.success}\")\n",
    "            print(f\"  HTML length: {len(result.data)} chars\")\n",
    "        else:\n",
    "            print(f\"  Error: {result.error}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 3: Batch URL Scraping\n",
    "\n",
    "Scrape multiple URLs concurrently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch scraping 2 URLs...\n",
      "\n",
      "Results: 2 responses\n",
      "\n",
      "=== URL 1: https://example.com ===\n",
      "  Success: True\n",
      "  Status: ready\n",
      "  Content length: 513 chars\n",
      "  Preview: <!doctype html><html lang=\"en\"><head><title>Example Domain</title><meta name=\"viewport\" content=\"wid...\n",
      "\n",
      "=== URL 2: https://www.iana.org/domains/reserved ===\n",
      "  Success: True\n",
      "  Status: ready\n",
      "  Content length: 10815 chars\n",
      "  Preview: \n",
      "<!doctype html>\n",
      "<html>\n",
      "<head>\n",
      "\t<title>IANA-managed Reserved Domains</title>\n",
      "\n",
      "\t<meta charset=\"utf-8\"...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "URLS = [\n",
    "    \"https://example.com\",\n",
    "    \"https://www.iana.org/domains/reserved\",\n",
    "]\n",
    "\n",
    "print(f\"Batch scraping {len(URLS)} URLs...\\n\")\n",
    "\n",
    "async with client:\n",
    "    results = await client.scrape_url(\n",
    "        url=URLS,\n",
    "        response_format=\"raw\"\n",
    "    )\n",
    "\n",
    "print(f\"Results: {len(results)} responses\\n\")\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"=== URL {i+1}: {URLS[i]} ===\")\n",
    "    print(f\"  Success: {result.success}\")\n",
    "    print(f\"  Status: {result.status}\")\n",
    "    if result.success and result.data:\n",
    "        content_len = len(result.data) if isinstance(result.data, str) else len(str(result.data))\n",
    "        print(f\"  Content length: {content_len} chars\")\n",
    "        print(f\"  Preview: {str(result.data)[:100]}...\")\n",
    "    else:\n",
    "        print(f\"  Error: {result.error}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 4: Timing Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Result Metadata ===\n",
      "url: https://www.iana.org/domains/reserved\n",
      "success: True\n",
      "status: ready\n",
      "method: web_unlocker\n",
      "root_domain: iana.org\n",
      "html_char_size: 10815\n",
      "\n",
      "=== Timing ===\n",
      "trigger_sent_at: 2026-01-29 21:14:52.185321+00:00\n",
      "data_fetched_at: 2026-01-29 21:14:54.939432+00:00\n",
      "\n",
      "Total time: 2.75 seconds\n"
     ]
    }
   ],
   "source": [
    "# Check timing metadata from last result\n",
    "print(\"=== Result Metadata ===\")\n",
    "print(f\"url: {result.url}\")\n",
    "print(f\"success: {result.success}\")\n",
    "print(f\"status: {result.status}\")\n",
    "print(f\"method: {result.method}\")\n",
    "print(f\"root_domain: {result.root_domain}\")\n",
    "print(f\"html_char_size: {result.html_char_size}\")\n",
    "print(\"\\n=== Timing ===\")\n",
    "print(f\"trigger_sent_at: {result.trigger_sent_at}\")\n",
    "print(f\"data_fetched_at: {result.data_fetched_at}\")\n",
    "\n",
    "if result.trigger_sent_at and result.data_fetched_at:\n",
    "    duration = (result.data_fetched_at - result.trigger_sent_at).total_seconds()\n",
    "    print(f\"\\nTotal time: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "### Web Unlocker Methods\n",
    "\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| `client.scrape_url(url, ...)` | Scrape URL(s) with Web Unlocker |\n",
    "\n",
    "### Parameters\n",
    "\n",
    "| Parameter | Description | Default |\n",
    "|-----------|-------------|--------|\n",
    "| `url` | Single URL or list of URLs | Required |\n",
    "| `zone` | Bright Data zone | `sdk_unlocker` |\n",
    "| `country` | Proxy country code (US, GB, etc.) | `\"\"` |\n",
    "| `response_format` | `\"raw\"` (HTML) | `\"raw\"` |\n",
    "| `method` | HTTP method (GET, POST, etc.) | `\"GET\"` |\n",
    "| `timeout` | Request timeout in seconds | 30 |\n",
    "\n",
    "### Response Fields\n",
    "\n",
    "| Field | Description |\n",
    "|-------|-------------|\n",
    "| `success` | Boolean indicating success |\n",
    "| `data` | HTML string |\n",
    "| `status` | Status (\"ready\", \"error\", etc.) |\n",
    "| `url` | The scraped URL |\n",
    "| `method` | Always \"web_unlocker\" |\n",
    "| `root_domain` | Extracted domain |\n",
    "| `html_char_size` | Size of HTML response |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
